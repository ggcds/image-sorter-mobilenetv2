
# ClassificaÃ§Ã£o de Imagens com MobileNetV2

Projeto desenvolvido como parte da disciplina **ResoluÃ§Ã£o de Problemas com Deep Learning** do MBA em BI & Data Science, Ibmec.

## ğŸ§  Objetivo

Utilizar o modelo prÃ©-treinado **MobileNetV2**, disponibilizado pelo TensorFlow, para realizar a **classificaÃ§Ã£o de imagens** a partir de categorias do conjunto de dados **ImageNet**. As imagens utilizadas nos testes foram retiradas do **COCO Dataset**.

## ğŸ”§ Tecnologias Utilizadas

- Python 3.x
- TensorFlow
- Matplotlib
- NumPy

## ğŸ“ Estrutura do Projeto

```
/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â””â”€â”€ val2017/          # Imagens de validaÃ§Ã£o originais COCO
â”‚   â””â”€â”€ val_classified/       # Imagens organizadas por classe prevista
â”œâ”€â”€ img_classifier.ipynb      # Notebook principal com o cÃ³digo de classificaÃ§Ã£o
â””â”€â”€ README.md                 # Este arquivo
```

## â–¶ï¸ Como Executar

1. Clone este repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/nome-do-repositorio.git
   cd nome-do-repositorio
   ```

2. Crie e ative um ambiente virtual opcional:
   ```bash
   python -m venv venv
   source venv/bin/activate  # ou venv\Scripts\activate no Windows
   ```

3. Instale as dependÃªncias:
   ```bash
   pip install tensorflow matplotlib
   ```

4. Baixe o conjunto val2017 do **COCO Dataset** e coloque as imagens em `datasets/val/val2017/`.

5. Execute o notebook:
   ```bash
   jupyter notebook img_classifier.ipynb
   ```

## ğŸ–¼ï¸ SaÃ­da Esperada

Para cada imagem em `datasets/val/val2017`, o notebook irÃ¡:

- Mostrar os trÃªs rÃ³tulos mais provÃ¡veis segundo o modelo MobileNetV2
- Exibir a imagem original com o rÃ³tulo de maior confianÃ§a
- Informar a probabilidade associada a cada classe prevista
- Copiar a imagem para uma subpasta em `datasets/val_classified/`, com o nome da classe prevista

## ğŸ—‚ï¸ Fonte dos Dados

As imagens foram retiradas do **COCO Dataset**  
https://cocodataset.org/#home

## ğŸ“ ImpressÃµes

Durante a execuÃ§Ã£o do cÃ³digo, foi possÃ­vel observar que o modelo MobileNetV2 apresenta um desempenho bastante satisfatÃ³rio ao identificar objetos predominantes em imagens simples. Sua capacidade de classificaÃ§Ã£o Ã© eficaz principalmente quando o objeto de interesse estÃ¡ bem destacado, centralizado e em um fundo neutro.

No entanto, ao lidar com imagens mais complexas, especialmente aquelas com mÃºltiplos elementos visuais, sobreposiÃ§Ã£o de objetos ou fundo poluÃ­do, o modelo tende a apresentar limitaÃ§Ãµes. Em muitos casos, ele reconhece apenas o objeto mais evidente ou realiza previsÃµes incorretas, o que Ã© compreensÃ­vel considerando que foi treinado com a base ImageNet, onde cada imagem possui apenas um rÃ³tulo principal.

Quanto Ã  organizaÃ§Ã£o do projeto, as alteraÃ§Ãµes propostas foram adaptadas de forma prÃ¡tica. Em vez de utilizar mÃºltiplos diretÃ³rios como treino, validaÃ§Ã£o e teste, optou-se por usar apenas um diretÃ³rio de entrada com imagens nÃ£o rotuladas. O modelo prÃ©-treinado foi entÃ£o utilizado para classificar automaticamente essas imagens, que foram organizadas em subpastas dentro da estrutura `datasets/val_classified`, com base no rÃ³tulo previsto. Essa abordagem facilitou a visualizaÃ§Ã£o dos resultados e permitiu analisar facilmente os acertos e erros de classificaÃ§Ã£o.

## ğŸ“¸ Exemplos de Resultados

- Imagem original com o rÃ³tulo previsto corretamente, com alta confianÃ§a (Zebra classificada como Zebra)

![alt text](image-2.png)

- Imagem original com o rÃ³tulo previsto incorretamente ou com baixa confianÃ§a (Girafa classificada como Zebra)

![alt text](image-3.png)

- VisualizaÃ§Ã£o da estrutura de diretÃ³rios gerada automaticamente em `datasets/val_classified`, mostrando imagens agrupadas por classe prevista

![alt text](image-4.png)

---

**Desenvolvido por Guilherme Caldas**  
MBA em BI & Data Science, Ibmec
